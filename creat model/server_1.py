# === Server-side Python Flask: Nh·∫≠n ·∫£nh t·ª´ ESP32-CAM v√† ph√°t hi·ªán ng√£ ===
from flask import Flask, request, jsonify
import numpy as np
import tensorflow as tf

app = Flask(__name__)

# Load m√¥ h√¨nh ph√°t hi·ªán ng√£
print("[INFO] Loading fall_detection TFLite model...")
interpreter = tf.lite.Interpreter(model_path="fall_model_int8.tflite")
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print("[INFO] Model loaded successfully.")

@app.route('/fall_detect', methods=['POST'])
def fall_detect():
    try:
        print("üü¢ [SERVER] Nh·∫≠n ·∫£nh t·ª´ ESP32-CAM...")

        # Nh·∫≠n d·ªØ li·ªáu ·∫£nh t·ª´ ESP32 g·ª≠i sang
        raw = np.frombuffer(request.data, dtype=np.uint8)

        # Chuy·ªÉn ƒë·ªïi uint8 ‚Üí int8 ƒë√∫ng nh∆∞ ESP32 x·ª≠ l√Ω
        image = raw ^ 0x80
        image = image.astype(np.int8).reshape((96, 96, 1))

        # Ch·∫°y m√¥ h√¨nh
        interpreter.set_tensor(input_details[0]['index'], [image])
        interpreter.invoke()

        output_data = interpreter.get_tensor(output_details[0]['index'])[0]
        print(f"[DEBUG] Output model: {output_data}")

        # X·ª≠ l√Ω fall score
        if isinstance(output_data, np.ndarray) and output_data.size == 1:
            fall_score = output_data.item()
        else:
            fall_score = output_data[1] if len(output_data) > 1 else 0.0

        print(f"üîç [SERVER] Fall score: {fall_score:.2f}")

        if fall_score > 0.7:
            print("üî¥ [SERVER] PH√ÅT HI·ªÜN NG∆Ø·ªúI NG√É!")
        else:
            print("‚úÖ [SERVER] Kh√¥ng ph√°t hi·ªán ng√£.")

        print("‚úÖ [SERVER] ƒê√£ x·ª≠ l√Ω v√† g·ª≠i k·∫øt qu·∫£ v·ªÅ ESP32.\n")

        return jsonify({'fall': bool(fall_score > 0.7)})

    except Exception as e:
        print("‚ùå [ERROR] L·ªói khi x·ª≠ l√Ω ·∫£nh nh·∫≠n t·ª´ ESP32:")
        print(e)
        return jsonify({'fall': False, 'error': str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)